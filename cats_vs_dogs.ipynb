{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2f3148",
   "metadata": {},
   "source": [
    "### Machine Learning Workshop example: Cats vs dogs\n",
    "\n",
    "This notebook shows how to train a convolutional neural network that distinguishes cats and dogs. \\\n",
    "For more information on image classification, check out this blog: [How to Classifiy Photos of Dogs and Cats (with 97% accuracy)](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-burke",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Dataset is available on [Kaggle](https://www.kaggle.com/c/dogs-vs-cats) - download and extract a folder called `train/` in your working directory.  \n",
    "\n",
    "- create a conda environment with required packages (in console): `conda create -n ml_workshop2 tensorflow-gpu` \\\n",
    "This requires your GPU to be CUDA-enabled - you may have to install additional drivers depending on your hardware.\n",
    "- alternative: train using CPU (much slower): `conda create -n ml_workshop2 tensorflow`\n",
    "- Install remaining libraries:\n",
    "\n",
    "        conda activate ml_workshop2\n",
    "\t\tconda install keras scikit-learn ipykernel pillow\n",
    "        python -m ipykernel install --user --name ml_workshop2 --display-name \"ML Workshop - cats vs. dogs\"\n",
    "- run in local browser: `jupyter notebook`\n",
    "- Alternative: run in VSCode with Python and Jupyter notebook extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba43bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete\n",
      "10.0 % complete\n",
      "20.0 % complete\n",
      "30.0 % complete\n",
      "40.0 % complete\n",
      "50.0 % complete\n",
      "60.0 % complete\n",
      "70.0 % complete\n",
      "80.0 % complete\n",
      "90.0 % complete\n",
      "(25000, 224, 224, 3) (25000,)\n"
     ]
    }
   ],
   "source": [
    "# load dogs vs cats dataset \n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "X, y = list(), list()\n",
    "image_size = (224, 224)\n",
    "# enumerate files in the directory\n",
    "progress = 0\n",
    "for file in listdir(folder):\n",
    "    if progress % 2500 == 0:\n",
    "        print(progress / 250, r\"% complete\")\n",
    "    \n",
    "    # determine class based on file name\n",
    "    output = 0.0\n",
    "    if file.startswith('cat'):\n",
    "        output = 1.0\n",
    "\n",
    "    photo = load_img(folder + file, target_size=image_size)\n",
    "\n",
    "    # convert to numpy array\n",
    "    photo = img_to_array(photo)\n",
    "    X.append(photo)\n",
    "    y.append(output)\n",
    "\n",
    "    progress += 1\n",
    "    \n",
    "# convert to a numpy arrays\n",
    "X = asarray(X)\n",
    "y = asarray(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "487e7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling using simple train/test split\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706bf719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using a pre-trained image classification model here and fine-tuning on our dataset\n",
    "# for more information about the general procedure, see https://en.wikipedia.org/wiki/Transfer_learning\n",
    "# for information about the base model, see https://keras.io/api/applications/vgg/\n",
    "\n",
    "def define_transfer_learning_model():\n",
    "    # load model\n",
    "    model = tensorflow.keras.applications.VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = tensorflow.keras.layers.Flatten()(model.layers[-1].output)\n",
    "    class1 = tensorflow.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = tensorflow.keras.layers.Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = tensorflow.keras.Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = tensorflow.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "transfer_learned_model = define_transfer_learning_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ff4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 155s 243ms/step - loss: 0.2066 - accuracy: 0.9661 - val_loss: 0.0636 - val_accuracy: 0.9714\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 168s 269ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0640 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25057617a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bit of black magic - data is centered using the same method as in the original training of the VGG16 model\n",
    "datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True)\n",
    "datagen.mean = [123.68, 116.779, 103.939]\n",
    "\n",
    "# dataset does not fit into the memory of my GPU - load data in batches\n",
    "train_generator = datagen.flow(X_train, y_train)\n",
    "test_generator = datagen.flow(X_test, y_test)\n",
    "\n",
    "transfer_learned_model.fit(train_generator, steps_per_epoch=len(train_generator), validation_data=test_generator, validation_steps=len(test_generator), epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6cf1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step\n",
      "Predicted probability of cat image #1 showing a cat: 1.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted probability of cat image #2 showing a cat: 1.0\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted probability of cat image #3 showing a cat: 1.0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted probability of cat image #4 showing a cat: 0.9300000071525574\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted probability of cat image #5 showing a cat: 0.9700000286102295\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicted probability of cat image #6 showing a cat: 0.8799999952316284\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted probability of dog image #1 showing a cat: 0.0\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted probability of dog image #2 showing a cat: 0.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted probability of dog image #3 showing a cat: 0.20000000298023224\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted probability of dog image #4 showing a cat: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, target_size=image_size)\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 3 channels\n",
    "\timg = img.reshape(1, *image_size, 3)\n",
    "\t# center pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img - [123.68, 116.779, 103.939]\n",
    "\treturn img\n",
    "\n",
    "for idx in range(1, 7):\n",
    "    pic = load_image(f\"saxi_ari_photos/saxi{idx}.jpg\")\n",
    "    pred = transfer_learned_model.predict(pic, verbose=True)[0][0]\n",
    "    print(f\"Predicted probability of cat image #{idx} showing a cat: {round(pred, 2)}\")\n",
    "\n",
    "for idx in range(1, 5):\n",
    "    pic = load_image(f\"saxi_ari_photos/arinka{idx}.jpg\")\n",
    "    pred = transfer_learned_model.predict(pic, verbose=True)[0][0]\n",
    "    print(f\"Predicted probability of dog image #{idx} showing a cat: {round(pred, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b9617ca95a02f4bb5900eb5f27668a1c624d7d28861326e6b909778853290b4"
  },
  "kernelspec": {
   "display_name": "ML Workshop - cats vs. dogs",
   "language": "python",
   "name": "ml_workshop2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
